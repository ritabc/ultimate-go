# Synchronization With Mutexes
## Use Atomic instructions for Code above

```go

// Go back to less precise int
var counter int

// Usually, this would be field in struct (which could not be copied if it has mutex inside of it!), not global variable
var mutex sync.Mutex

func main () {

    // number of G's to use
    const grs = 2

    var wg sync.WaitGroup
    wg.Add(grs)

    // Create 2 goroutines
    for i := 0; i < grs; i++ {
        go func() {
            for count := 0; count < 2; count++ {

                // Only allow 1 goroutine through this critical section at a time:
                mutex.Lock() 
                { // Can use artificial code block : for visual purposes, but does create new level of scope
                    // Read: Capture value of counter
                    value := counter

                    // Modify: Increment local value of counter
                    value++

                    // Write: Store value back into Counter
                    counter = value
                }
                mutex.Unlock()
                // Release the lock and allow any waiting goroutine through
            }
        wg.Done()
        }()
    }

    wg.Wait()
    
    fmt.Prinln("Final Counter: ", counter)
}
```
* Put lines of code (LOC) inside room
* Schedule works as bouncer, not allowing more than 1 goroutine to access room / execute LOC at a time
* When goroutines arrive, they each request a Lock from bouncer
* A lock is a blocking call
* Scheduler gives a lock to 1 goroutine at a time - does NOT depend on who got there first 
* Goroutine that's in the room executes LOC, then calls unlock: 
    - this frees scheduler to give a lock to another goroutine
* Real cost to mutexes: latency
    - more goroutines waiting to get into room, and the longer each goroutine stays in room, the more latency exists
    - Ensure that LOC are short as possible
    - BUT, Also must Ensure that LOC are atomic
* HELPFUL RULE: The same function that calls Lock MUST also call Unlock - they must alway be together
    - can also use defer
* Note 1 goroutine can only call Lock once - even if it unlocks, it shouldn't request back into the room, or into a new room

## RWMutex
* Allows us to have multiple reads across 1 write
```go
import(
"fmt"
	"math/rand"
	"sync"
	"sync/atomic"
	"time"
)

// data is slice that will be shared
var data []string

// rwMutex is used to define a critical section of code
var rwMutex sync.RWMutex

// Number of reads occurring at any given time
var readCount int64

func init() {
    rand.Seed(time.Now().UnixNano())
}

func main() {
    var wg sync.WaitGroup
    wg.Add(1)

    // Writer goroutine
    go func() {
        for i := 0; i < 10; i++ {
            time.Sleep(time.Duration(rand.Intn(100)) * time.Millisecond)
            writer(1)
        }
        wg.Done()
    }()

    // Create eight reader goroutines
    for i := 0; i < 8; i++ {
        go func(id int) {
            for { 
                reader(id)
            }
        }(i)
    }

    // Wait for write goroutine to finish
    wg.Wait()
    fmt.Println("Program Complete")
}

// writer adds a new string to the slice at random intervals
func writer(i int) {

    // Only allow 1 goroutine to read/write to slice at a time
    rwMutex.Lock()
    {
        // Capture current read count
        // Keep this safe through we can due w/o this call
        rc := atomic.LoadInt64(&readCount)

        // Perform some work since we have a full lock
        fmt.Printf("****> : Performing Write : RCount[%d]\n", rc)
        data = append9data, fmt.Sprintf("String: %d", i)
    }

    rwMutex.Unlock()
    // Release the lock
}

// reader wakes up and iterates over the data slice
func reader(id int) {

    // Any goroutine can read when no write operation is taking place
    rwMutex.RLock()
    {
        // Increment read count value by 1
        rc := atomic.AddInt64(&readCount, 1)

        // Perform some read work and display values
        time.Sleep(time.Duration(rand.Intn(10)) * time.Millisecond)
        fmt.Printf("%d : Performing Read : Length[%d] RCount[%d]\n", id, len(data), rc)

        // Decrement read count value by 1
        atomic.AddInt64(&readCount, -1)
    }

    // Release the read lock
    rwMutex.RUnlock()

}
```
* What is happening?
    - launch write goroutine to write to data
    - Have 8 read goroutines which will read data, all of them can read at same time
    - Lock and Unlock surround code that should be THE ONLY code running
        - when writer goroutine requests lock, scheduler waits till all reader goroutines are done and are RUnlock'ed, then writer goroutine gets Lock. Until writer calls Unlock, only that goroutine executes- nothing else happens 
    - RLock and RUnlock surround code that allows any goroutine thats reading only to execute